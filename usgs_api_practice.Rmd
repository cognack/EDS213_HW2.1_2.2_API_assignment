---
title: "usgs_api_practice"
author: "Steven Cognac"
date: "10/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dataRetrieval) 
library(tidyverse)
library(metajam)
library(here)

```

USGS API sources
 - https://cran.r-project.org/web/packages/dataRetrieval/vignettes/dataRetrieval.html#daily-data
 - https://dashboard.waterdata.usgs.gov/app/nwd/?region=lower48&aoi=default
 
Metajam sources
 - https://brunj7.github.io/EDS-213-metadata/slides/metajam_intro.html#3
 

# Example 1
## retrieve USGS stream guage data at the Ventura River from 2019-10-01 to 2020-10-05

```{r}
# ventura river
siteNumber <- 11118500
parameterCd <- c("00060", "00010") # discharge & temperature
startDate <- "2019-10-01"
endDate <- "2020-10-05"

# create database based on above parameters
discharge <- readNWISdv(siteNumber, parameterCd, startDate, endDate)

```

## plotting data

```{r}

ventura_plot <- ggplot(data = discharge, aes(x = Date, y = X_00060_00003)) +
  geom_line() +
  labs(y = paste(c("Discharge", expression(ft^3/s))))
       
ventura_plot
```
## retrieve data for beginnning record of discharge recording
```{r}

# ventura river
siteNumber <- 11118500
parameterCd <- c("00060", "00065") # discharge & temperature
startDate <- "" # grabs entire dataset from beginning of recording
endDate <- "2020-10-05"

# create database based on above parameters
discharge2 <- readNWISdv(siteNumber, parameterCd, startDate, endDate)


```

## discharge2 plot
```{r}
ventura_plot2 <- ggplot(data = discharge2, aes(x = Date, y = X_00060_00003)) +
  geom_line() +
  labs(y = "Discharge")
       
ventura_plot2
```

# Example 2: Metajam
## Exercise
```{r}
# how to knit without rerunning code
# knitr::opts_chunk$set(eval = FALSE)

# downloading data
data_url <- "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A7fc6f6db-c5ea-426a-a743-1f2edafb43b8"
path <- here("metajam")

# download csv files with metajam
data_path <- download_d1_data(data_url, path)



```

## read in .csv data with metajam
```{r}

# download the data based on the file path with metajam. 
# creates a list of all data, which has pre-defned names
data <- read_d1_files(data_path)

# view metadata
data$attribute_metadata %>% view()

```


## Write a piece of code that will compute the percentage of Alaskan household speaking only English for the year 2009 to 2015
```{r}
# get the dataframe
hh_data <- data$data
hh_data

alaska_data <- hh_data %>% 
  filter(SASAP.Region == "Alaska Peninsula and Aleutian Islands",
         Year == c("2009", "2015")) %>% 
  group_by(Year) %>% 
  summarise(speak_only_english) %>% 
  view()
  


```

